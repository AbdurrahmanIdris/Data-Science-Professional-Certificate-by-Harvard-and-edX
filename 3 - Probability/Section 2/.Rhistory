?seq
second = (-b-sqrt(b^2-4*a*c))/(2*a)
a <- 2
b <- -1
c <- -4
first = (-b+sqrt(b^2-4*a*c))/(2*a)
second = (-b-sqrt(b^2-4*a*c))/(2*a)
source('~/.active-rstudio-document', echo=TRUE)
a <- 2
b <- -1
c <- -4
first = (-b+sqrt(b^2-(4*a*c)))/(2*a)
second = (-b-sqrt(b^2-(4*a*c)))/(2*a)
a <- 2
b <- -1
c <- -4
first = (-b+sqrt(b^2-(4*a*c)))/(2*a)
second = (-b-sqrt(b^2-(4*a*c)))/(2*a)
first
second
log4(1024)
log(1024,4)
install.packages("dslabs")
library(dslabs)
data("movielens")
data(movielens)
str(movielens)
lev <- movielens$genres
nlevels(lev)
time <- time/60
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
time
speed
name[which.max(speed)]
library(dslabs)
data("heights")
prop.table(table(heights))
summary(heights$height)
p <- seq(0.01,0.99,0.01)
quantile(heights$height,p)
qnorm(p, 69, 3)
p <- seq(0.05, 0.95, 0.05)
sample_quantiles <- quantile(heights$height,p)
theoretical_quantiles <- qnorm(p, mean(heights$height), sd(heights$height))
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
library(tidyverse)
library(dplyr)
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
install.packages(ggplot2)
install.packages("ggplot2")
library(ggplot2)
qplot(theoretical_quantiles, sample_quantiles) + geom_abline()
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
install.packages("ggthemes")
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
install.packages("ggrepel")
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Other examples using ggplot.R', echo=TRUE)
install.packages("gridExtra")
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Other examples using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Other examples using ggplot.R', echo=TRUE)
source('E:/Faculty Of Engineering/Online courses/edX/Data Science Professional Certificate - Harvard/2 - Visualization/Other examples using ggplot.R', echo=TRUE)
?aes
setwd("E:/FacultyOfEngineering/online_courses/edX/Data Science Professional Certificate - Harvard/3 - Probability")
source('E:/FacultyOfEngineering/online_courses/edX/Data Science Professional Certificate - Harvard/3 - Probability/section1_assignment3_Esophageal cancer and alcohol-tobacco use, part 1.R', echo=TRUE)
cases_with_highest_alcgp / controls_with_highest_alcgp
cases_with_highest_alcgp <- sum(highest_alcgp$ncases)
controls_with_highest_alcgp <- sum(highest_alcgp$ncontrols)
p_cases_high_alc <- cases_with_highest_alcgp / all_cases
p_controls_high_alc <- controls_with_highest_alcgp / all_controls
p_cases_high_alc / p_controls_high_alc
levels(esoph$tobgp)
p_cases_high_alc / p_controls_high_alc
controls_in_high_tob <- esoph %>%
filter(tobgp == "30+") %>%
pull(ncontrols)%>%
sum()
p_controls_high_tob <- controls_in_high_tob / all_controls
p_controls_high_tob
p_controls_high_alc * p_controls_high_tob
levels(esoph$alcgp)
p_controls_high_tob <- controls_in_high_tob / all_controls
controls_in_high_tob_and_high_alc <- esoph %>%
filter(tobgp == "30+" & alcgp == "120+") %>%
pull(ncontrols)%>%
sum()
p_controls_in_high_tob_and_high_alc <- controls_in_high_tob_and_high_alc / all_controls
p_controls_in_high_tob_and_high_alc
p_controls_high_alc_or_tob <- p_controls_high_alc + p_controls_high_tob - p_controls_in_high_tob_and_high_alc
p_controls_high_alc_or_tob
setwd("E:/FacultyOfEngineering/online_courses/edX/Data Science Professional Certificate - Harvard/3 - Probability/Section 1")
setwd("E:/FacultyOfEngineering/online_courses/edX/Data Science Professional Certificate - Harvard/3 - Probability/Section 2")
version
set.seed(16, sample.kind = "Rounding")
act_scores <- rnorm(10000,20.9,5.7)
mean(act_scores)
sd(act_scores)
dnorm(36,mean(act_scores),sd(act_scores))
dnorm(36,mean(act_scores),sd(act_scores)) * 10000
set.seed(16, sample.kind = "Rounding")
act_scores <- rnorm(10000,20.9,5.7)
dnorm(36,mean(act_scores),sd(act_scores)) * 10000
1 - pnorm(36,mean(act_scores),sd(act_scores))
(1 - pnorm(36,mean(act_scores),sd(act_scores))) * 10000
#(1 - pnorm(36,mean(act_scores),sd(act_scores)))
act_scores >= 36
#(1 - pnorm(36,mean(act_scores),sd(act_scores)))
mean(act_scores >= 36)
#(1 - pnorm(36,mean(act_scores),sd(act_scores)))
sum(act_scores >= 36)
#In act_scores, what is the probability of an ACT score greater than 30?
1 - pnorm(30,mean(act_scores),sd(act_scores))
#In act_scores, what is the probability of an ACT score less than or equal to 10?
pnorm(10,mean(act_scores),sd(act_scores))
?seq
#Set x equal to the sequence of integers 1 to 36.
#Use dnorm to determine the value of the probability density function over x
#given a mean of 20.9 and standard deviation of 5.7; save the result as f_x.
#Plot x against f_x.
x <- seq(1,36,by = 1)
max(x)
x <- seq(1,36,by = 1)
f_x = dnorm(x,20.9,5.7)
plot(x,f_x)
#What is the probability of a Z-score greater than 2 (2 standard deviations above the mean)?
pnorm(mean(act_scores) + 2 * sd(act_scores),mean(act_scores),sd(act_scores))
#What is the probability of a Z-score greater than 2 (2 standard deviations above the mean)?
1 - pnorm(mean(act_scores) + 2 * sd(act_scores),mean(act_scores),sd(act_scores))
#What is the probability of a Z-score greater than 2 (2 standard deviations above the mean)?
p_z_greater_than_two <- 1 - pnorm(mean(act_scores) + 2 * sd(act_scores),mean(act_scores),sd(act_scores))
#What ACT score value corresponds to 2 standard deviations above the mean (Z = 2)?
qnorm()
#What is the probability of a Z-score greater than 2 (2 standard deviations above the mean)?
p_z_greater_than_two <- 1 - pnorm(mean(act_scores) + 2 * sd(act_scores),mean(act_scores),sd(act_scores))
#What ACT score value corresponds to 2 standard deviations above the mean (Z = 2)?
qnorm(p_z_greater_than_two,mean(act_scores),sd(act_scores))
#What ACT score value corresponds to 2 standard deviations above the mean (Z = 2)?
dnorm(p_z_greater_than_two,mean(act_scores),sd(act_scores))
#What ACT score value corresponds to 2 standard deviations above the mean (Z = 2)?
dnorm(2,mean(act_scores),sd(act_scores))
#A Z-score of 2 corresponds roughly to the 97.5th percentile.
#Use qnorm() to determine the 97.5th percentile of normally distributed data with the mean and standard deviation observed in act_scores.
#What is the 97.5th percentile of act_scores?
qnorm(0.975,mean(act_scores),sd(act_scores))
#Write a function that takes a value and produces the probability of an ACT score less than or equal to that value (the CDF).
#Apply this function to the range 1 to 36.
cdf <- function(a) mean(act_scores<=a)
sapply(x,cdf)
paste(x,sapply(x,cdf))
qnorm(0.95,mean(act_scores),sd(act_scores))
set.seed(16, sample.kind = "Rounding")
act_scores <- rnorm(10000,20.9,5.7)
#In act_scores, how many perfect scores are there out of 10,000 simulated tests?
sum(act_scores >= 36)
#In act_scores, what is the probability of an ACT score greater than 30?
1 - pnorm(30,mean(act_scores),sd(act_scores))
#In act_scores, what is the probability of an ACT score less than or equal to 10?
pnorm(10,mean(act_scores),sd(act_scores))
#Set x equal to the sequence of integers 1 to 36.
#Use dnorm to determine the value of the probability density function over x
#given a mean of 20.9 and standard deviation of 5.7; save the result as f_x.
#Plot x against f_x.
x <- seq(1,36,by = 1)
f_x = dnorm(x,20.9,5.7)
plot(x,f_x)
#What is the probability of a Z-score greater than 2 (2 standard deviations above the mean)?
p_z_greater_than_two <- 1 - pnorm(mean(act_scores) + 2 * sd(act_scores),mean(act_scores),sd(act_scores))
#What ACT score value corresponds to 2 standard deviations above the mean (Z = 2)?
2 * sd(act_scores) + mean(act_scores)
#A Z-score of 2 corresponds roughly to the 97.5th percentile.
#Use qnorm() to determine the 97.5th percentile of normally distributed data with the mean and standard deviation observed in act_scores.
#What is the 97.5th percentile of act_scores?
qnorm(0.975,mean(act_scores),sd(act_scores))
#Write a function that takes a value and produces the probability of an ACT score less than or equal to that value (the CDF).
#Apply this function to the range 1 to 36.
cdf <- function(a) mean(act_scores<=a)
paste(x,sapply(x,cdf))
#What is the expected 95th percentile of ACT scores?
qnorm(0.95,mean(act_scores),sd(act_scores))
#What is the expected 95th percentile of ACT scores?
qnorm(0.95,20.9,5.7)
#What is the expected 95th percentile of ACT scores?
qnorm(0.95,mean(act_scores),sd(act_scores))
?quantile
sample_quantiles <- quantile(act_scores,p)
p <- seq(0.01, 0.99, 0.01)
sample_quantiles <- quantile(act_scores,p)
sample_quantiles
p <- seq(0.01, 0.99, 0.01)
sample_quantiles <- quantile(act_scores,p, names = TRUE)
sample_quantiles
p <- seq(0.01, 0.99, 0.01)
sample_quantiles <- quantile(act_scores,p, names = TRUE)
names(sample_quantiles[max(which(sample_quantiles < 26))])
#In what percentile is a score of 26?
p <- seq(0.01, 0.99, 0.01)
sample_quantiles <- quantile(act_scores,p, names = TRUE)
names(sample_quantiles[max(which(sample_quantiles < 26))])
theoretical_quantiles <- qnorm(p,20.9,5.7)
plot(theoretical_quantiles,sample_quantiles)
# sampling model 1: define urn, then sample
color <- rep(c("Black", "Red", "Green"), c(18, 18, 2)) # define the urn for the sampling model
color
color <- rep(c("Black", "Red", "Green"), c(18, 18, 2)) # define the urn for the sampling model
n <- 1000
X <- sample(ifelse(color == "Red", -1, 1), n, replace = TRUE)
X[1:10]
# sampling model 2: define urn inside sample function by noting probabilities
x <- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19))    # 1000 independent draws
S <- sum(x)    # total winnings = sum of draws
S
n <- 1000    # number of roulette players
B <- 10000    # number of Monte Carlo experiments
S <- replicate(B, {
X <- sample(c(-1,1), n, replace = TRUE, prob = c(9/19, 10/19))    # simulate 1000 spins
sum(X)    # determine total profit
})
mean(S < 0)    # probability of the casino losing money
library(tidyverse)
s <- seq(min(S), max(S), length = 100)    # sequence of 100 values across range of S
normal_density <- data.frame(s = s, f = dnorm(s, mean(S), sd(S))) # generate normal density for S
data.frame (S = S) %>%    # make data frame of S for histogram
ggplot(aes(S, ..density..)) +
geom_histogram(color = "black", binwidth = 10) +
ylab("Probability") +
geom_line(data = normal_density, mapping = aes(s, f), color = "blue")
